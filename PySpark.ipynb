{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "aOxHjZjCkF5j",
        "D_Zn5ywjkBnX",
        "YyVjqhG4pChj"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Intro"
      ],
      "metadata": {
        "id": "aOxHjZjCkF5j"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SWG61g7pafcf",
        "outputId": "6c7d70fe-8335-4058-b444-f54413f7ce2b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.12/dist-packages (4.0.1)\n",
            "Requirement already satisfied: py4j==0.10.9.9 in /usr/local/lib/python3.12/dist-packages (from pyspark) (0.10.9.9)\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark\n",
        "\n",
        "# upload file -> present in downloads\n",
        "# test1.csv\n",
        "# test2.csv\n",
        "# test3.csv\n",
        "# tips.csv"
      ],
      "metadata": {
        "id": "Eaciko5PatsQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "pd.read_csv('test1.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "2MbJZbAKa2df",
        "outputId": "ee45c9d5-99b5-4174-b9b7-f70392e93512"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        Name  age  Experience  Salary\n",
              "0      Krish   31          10   30000\n",
              "1  Sudhanshu   30           8   25000\n",
              "2      Sunny   29           4   20000\n",
              "3       Paul   24           3   20000\n",
              "4     Harsha   21           1   15000\n",
              "5    Shubham   23           2   18000"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e2f5e758-2704-4d71-b649-92f724c1b81d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Name</th>\n",
              "      <th>age</th>\n",
              "      <th>Experience</th>\n",
              "      <th>Salary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Krish</td>\n",
              "      <td>31</td>\n",
              "      <td>10</td>\n",
              "      <td>30000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Sudhanshu</td>\n",
              "      <td>30</td>\n",
              "      <td>8</td>\n",
              "      <td>25000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Sunny</td>\n",
              "      <td>29</td>\n",
              "      <td>4</td>\n",
              "      <td>20000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Paul</td>\n",
              "      <td>24</td>\n",
              "      <td>3</td>\n",
              "      <td>20000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Harsha</td>\n",
              "      <td>21</td>\n",
              "      <td>1</td>\n",
              "      <td>15000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Shubham</td>\n",
              "      <td>23</td>\n",
              "      <td>2</td>\n",
              "      <td>18000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e2f5e758-2704-4d71-b649-92f724c1b81d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e2f5e758-2704-4d71-b649-92f724c1b81d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e2f5e758-2704-4d71-b649-92f724c1b81d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"pd\",\n  \"rows\": 6,\n  \"fields\": [\n    {\n      \"column\": \"Name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"Krish\",\n          \"Sudhanshu\",\n          \"Shubham\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4,\n        \"min\": 21,\n        \"max\": 31,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          31,\n          30,\n          23\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Experience\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3,\n        \"min\": 1,\n        \"max\": 10,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          10,\n          8,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Salary\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5354,\n        \"min\": 15000,\n        \"max\": 30000,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          25000,\n          18000,\n          20000\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder.appName('Practice').getOrCreate()"
      ],
      "metadata": {
        "id": "ViSbD84Ia2g7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "0q-e-ba4a2kj",
        "outputId": "743025cc-cb84-4071-b34e-a10457e4cad6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x79aa63132e70>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://f8f7a0b1b663:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v4.0.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>Practice</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark = spark.read.csv('test1.csv')\n",
        "df_pyspark.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ap5YME-da2u9",
        "outputId": "ed878d71-5404-4cb1-ddc3-c8bc5e805a68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---+----------+------+\n",
            "|      _c0|_c1|       _c2|   _c3|\n",
            "+---------+---+----------+------+\n",
            "|     Name|age|Experience|Salary|\n",
            "|    Krish| 31|        10| 30000|\n",
            "|Sudhanshu| 30|         8| 25000|\n",
            "|    Sunny| 29|         4| 20000|\n",
            "|     Paul| 24|         3| 20000|\n",
            "|   Harsha| 21|         1| 15000|\n",
            "|  Shubham| 23|         2| 18000|\n",
            "+---------+---+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark = spark.read.option('header', 'true').csv('test1.csv')"
      ],
      "metadata": {
        "id": "LCmIccRQf5gN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AlbxEZsBf_21",
        "outputId": "291e5ec0-393a-433f-cf29-deae675bb5a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---+----------+------+\n",
            "|     Name|age|Experience|Salary|\n",
            "+---------+---+----------+------+\n",
            "|    Krish| 31|        10| 30000|\n",
            "|Sudhanshu| 30|         8| 25000|\n",
            "|    Sunny| 29|         4| 20000|\n",
            "|     Paul| 24|         3| 20000|\n",
            "|   Harsha| 21|         1| 15000|\n",
            "|  Shubham| 23|         2| 18000|\n",
            "+---------+---+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(df_pyspark)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "jEpx5FNjf96s",
        "outputId": "51e3c013-650a-4da1-e11d-b8caa658b596"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pyspark.sql.classic.dataframe.DataFrame"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>pyspark.sql.classic.dataframe.DataFrame</b><br/>def __init__(jdf: &#x27;JavaObject&#x27;, sql_ctx: Union[&#x27;SQLContext&#x27;, &#x27;SparkSession&#x27;])</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.12/dist-packages/pyspark/sql/classic/dataframe.py</a>A distributed collection of data grouped into named columns.\n",
              "\n",
              ".. versionadded:: 1.3.0\n",
              "\n",
              ".. versionchanged:: 3.4.0\n",
              "    Supports Spark Connect.\n",
              "\n",
              "Examples\n",
              "--------\n",
              "A :class:`DataFrame` is equivalent to a relational table in Spark SQL,\n",
              "and can be created using various functions in :class:`SparkSession`:\n",
              "\n",
              "&gt;&gt;&gt; people = spark.createDataFrame([\n",
              "...     {&quot;deptId&quot;: 1, &quot;age&quot;: 40, &quot;name&quot;: &quot;Hyukjin Kwon&quot;, &quot;gender&quot;: &quot;M&quot;, &quot;salary&quot;: 50},\n",
              "...     {&quot;deptId&quot;: 1, &quot;age&quot;: 50, &quot;name&quot;: &quot;Takuya Ueshin&quot;, &quot;gender&quot;: &quot;M&quot;, &quot;salary&quot;: 100},\n",
              "...     {&quot;deptId&quot;: 2, &quot;age&quot;: 60, &quot;name&quot;: &quot;Xinrong Meng&quot;, &quot;gender&quot;: &quot;F&quot;, &quot;salary&quot;: 150},\n",
              "...     {&quot;deptId&quot;: 3, &quot;age&quot;: 20, &quot;name&quot;: &quot;Haejoon Lee&quot;, &quot;gender&quot;: &quot;M&quot;, &quot;salary&quot;: 200}\n",
              "... ])\n",
              "\n",
              "Once created, it can be manipulated using the various domain-specific-language\n",
              "(DSL) functions defined in: :class:`DataFrame`, :class:`Column`.\n",
              "\n",
              "To select a column from the :class:`DataFrame`, use the apply method:\n",
              "\n",
              "&gt;&gt;&gt; age_col = people.age\n",
              "\n",
              "A more concrete example:\n",
              "\n",
              "&gt;&gt;&gt; # To create DataFrame using SparkSession\n",
              "... department = spark.createDataFrame([\n",
              "...     {&quot;id&quot;: 1, &quot;name&quot;: &quot;PySpark&quot;},\n",
              "...     {&quot;id&quot;: 2, &quot;name&quot;: &quot;ML&quot;},\n",
              "...     {&quot;id&quot;: 3, &quot;name&quot;: &quot;Spark SQL&quot;}\n",
              "... ])\n",
              "\n",
              "&gt;&gt;&gt; people.filter(people.age &gt; 30).join(\n",
              "...     department, people.deptId == department.id).groupBy(\n",
              "...     department.name, &quot;gender&quot;).agg(\n",
              "...         {&quot;salary&quot;: &quot;avg&quot;, &quot;age&quot;: &quot;max&quot;}).sort(&quot;max(age)&quot;).show()\n",
              "+-------+------+-----------+--------+\n",
              "|   name|gender|avg(salary)|max(age)|\n",
              "+-------+------+-----------+--------+\n",
              "|PySpark|     M|       75.0|      50|\n",
              "|     ML|     F|      150.0|      60|\n",
              "+-------+------+-----------+--------+\n",
              "\n",
              "Notes\n",
              "-----\n",
              "A DataFrame should only be created as described above. It should not be directly\n",
              "created via using the constructor.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 105);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yQ1uuPwTa227",
        "outputId": "c2936a09-92b1-47fa-d42b-cbb90be44221"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Name: string (nullable = true)\n",
            " |-- age: string (nullable = true)\n",
            " |-- Experience: string (nullable = true)\n",
            " |-- Salary: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 1\n",
        "\n",
        "- pyspark dataframe\n",
        "- reading the dataset\n",
        "- checking the datatypes of the column (schema)\n",
        "- selecting columns and indexing\n",
        "- check describe option similar to pandas\n",
        "- adding columns\n",
        "- dropping columns\n",
        "- renaming columns"
      ],
      "metadata": {
        "id": "D_Zn5ywjkBnX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder.appName('Practice').getOrCreate()"
      ],
      "metadata": {
        "id": "YjCbadJLa25w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "_mKbwcpRa28b",
        "outputId": "bf9f2033-3ee0-4c28-ce12-85fa7294fa7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x79aa63132e70>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://f8f7a0b1b663:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v4.0.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>Practice</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# read the dataset\n",
        "df_pyspark = spark.read.option('header', 'true').csv('test1.csv', inferSchema = True)"
      ],
      "metadata": {
        "id": "8iXwfRO3a2-s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.printSchema()\n",
        "\n",
        "# it takes all the entries to be \"STRING\" until and unless we specify it.\n",
        "# inferSchema = True (it will give us the original datatype it is in the raw data)\n",
        "# nullable = true (it can have null values)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N4ZcuZiva3BH",
        "outputId": "7bd34fbf-839e-4841-e6b0-07861ad75a15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Name: string (nullable = true)\n",
            " |-- age: integer (nullable = true)\n",
            " |-- Experience: integer (nullable = true)\n",
            " |-- Salary: integer (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark = spark.read.csv('test1.csv', header=True,inferSchema=True)\n",
        "\n",
        "# another way of reading a .csv file"
      ],
      "metadata": {
        "id": "g8aJrP8Za3DT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(df_pyspark)\n",
        "\n",
        "# DataFrame is one kind of datastructure."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "oxuqbPPZltzG",
        "outputId": "26fff9ae-c77d-41e6-c2cb-c728483e7123"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pyspark.sql.classic.dataframe.DataFrame"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>pyspark.sql.classic.dataframe.DataFrame</b><br/>def __init__(jdf: &#x27;JavaObject&#x27;, sql_ctx: Union[&#x27;SQLContext&#x27;, &#x27;SparkSession&#x27;])</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.12/dist-packages/pyspark/sql/classic/dataframe.py</a>A distributed collection of data grouped into named columns.\n",
              "\n",
              ".. versionadded:: 1.3.0\n",
              "\n",
              ".. versionchanged:: 3.4.0\n",
              "    Supports Spark Connect.\n",
              "\n",
              "Examples\n",
              "--------\n",
              "A :class:`DataFrame` is equivalent to a relational table in Spark SQL,\n",
              "and can be created using various functions in :class:`SparkSession`:\n",
              "\n",
              "&gt;&gt;&gt; people = spark.createDataFrame([\n",
              "...     {&quot;deptId&quot;: 1, &quot;age&quot;: 40, &quot;name&quot;: &quot;Hyukjin Kwon&quot;, &quot;gender&quot;: &quot;M&quot;, &quot;salary&quot;: 50},\n",
              "...     {&quot;deptId&quot;: 1, &quot;age&quot;: 50, &quot;name&quot;: &quot;Takuya Ueshin&quot;, &quot;gender&quot;: &quot;M&quot;, &quot;salary&quot;: 100},\n",
              "...     {&quot;deptId&quot;: 2, &quot;age&quot;: 60, &quot;name&quot;: &quot;Xinrong Meng&quot;, &quot;gender&quot;: &quot;F&quot;, &quot;salary&quot;: 150},\n",
              "...     {&quot;deptId&quot;: 3, &quot;age&quot;: 20, &quot;name&quot;: &quot;Haejoon Lee&quot;, &quot;gender&quot;: &quot;M&quot;, &quot;salary&quot;: 200}\n",
              "... ])\n",
              "\n",
              "Once created, it can be manipulated using the various domain-specific-language\n",
              "(DSL) functions defined in: :class:`DataFrame`, :class:`Column`.\n",
              "\n",
              "To select a column from the :class:`DataFrame`, use the apply method:\n",
              "\n",
              "&gt;&gt;&gt; age_col = people.age\n",
              "\n",
              "A more concrete example:\n",
              "\n",
              "&gt;&gt;&gt; # To create DataFrame using SparkSession\n",
              "... department = spark.createDataFrame([\n",
              "...     {&quot;id&quot;: 1, &quot;name&quot;: &quot;PySpark&quot;},\n",
              "...     {&quot;id&quot;: 2, &quot;name&quot;: &quot;ML&quot;},\n",
              "...     {&quot;id&quot;: 3, &quot;name&quot;: &quot;Spark SQL&quot;}\n",
              "... ])\n",
              "\n",
              "&gt;&gt;&gt; people.filter(people.age &gt; 30).join(\n",
              "...     department, people.deptId == department.id).groupBy(\n",
              "...     department.name, &quot;gender&quot;).agg(\n",
              "...         {&quot;salary&quot;: &quot;avg&quot;, &quot;age&quot;: &quot;max&quot;}).sort(&quot;max(age)&quot;).show()\n",
              "+-------+------+-----------+--------+\n",
              "|   name|gender|avg(salary)|max(age)|\n",
              "+-------+------+-----------+--------+\n",
              "|PySpark|     M|       75.0|      50|\n",
              "|     ML|     F|      150.0|      60|\n",
              "+-------+------+-----------+--------+\n",
              "\n",
              "Notes\n",
              "-----\n",
              "A DataFrame should only be created as described above. It should not be directly\n",
              "created via using the constructor.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 105);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GHnCcLUnlt2A",
        "outputId": "c6ef4e5b-a273-4eaf-9557-131c75635f46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Name', 'age', 'Experience', 'Salary']"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.head(3)\n",
        "\n",
        "# we get in LIST format"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lo2cDkUrlt47",
        "outputId": "45ba169e-f326-457b-f621-682ee7837a6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(Name='Krish', age=31, Experience=10, Salary=30000),\n",
              " Row(Name='Sudhanshu', age=30, Experience=8, Salary=25000),\n",
              " Row(Name='Sunny', age=29, Experience=4, Salary=20000)]"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(df_pyspark.select('Name'))\n",
        "\n",
        "# if you want to select sincle column/field"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "nhDE19jnlt73",
        "outputId": "ce1034b3-d537-4ffb-88b8-2d30fac75854"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pyspark.sql.classic.dataframe.DataFrame"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>pyspark.sql.classic.dataframe.DataFrame</b><br/>def __init__(jdf: &#x27;JavaObject&#x27;, sql_ctx: Union[&#x27;SQLContext&#x27;, &#x27;SparkSession&#x27;])</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.12/dist-packages/pyspark/sql/classic/dataframe.py</a>A distributed collection of data grouped into named columns.\n",
              "\n",
              ".. versionadded:: 1.3.0\n",
              "\n",
              ".. versionchanged:: 3.4.0\n",
              "    Supports Spark Connect.\n",
              "\n",
              "Examples\n",
              "--------\n",
              "A :class:`DataFrame` is equivalent to a relational table in Spark SQL,\n",
              "and can be created using various functions in :class:`SparkSession`:\n",
              "\n",
              "&gt;&gt;&gt; people = spark.createDataFrame([\n",
              "...     {&quot;deptId&quot;: 1, &quot;age&quot;: 40, &quot;name&quot;: &quot;Hyukjin Kwon&quot;, &quot;gender&quot;: &quot;M&quot;, &quot;salary&quot;: 50},\n",
              "...     {&quot;deptId&quot;: 1, &quot;age&quot;: 50, &quot;name&quot;: &quot;Takuya Ueshin&quot;, &quot;gender&quot;: &quot;M&quot;, &quot;salary&quot;: 100},\n",
              "...     {&quot;deptId&quot;: 2, &quot;age&quot;: 60, &quot;name&quot;: &quot;Xinrong Meng&quot;, &quot;gender&quot;: &quot;F&quot;, &quot;salary&quot;: 150},\n",
              "...     {&quot;deptId&quot;: 3, &quot;age&quot;: 20, &quot;name&quot;: &quot;Haejoon Lee&quot;, &quot;gender&quot;: &quot;M&quot;, &quot;salary&quot;: 200}\n",
              "... ])\n",
              "\n",
              "Once created, it can be manipulated using the various domain-specific-language\n",
              "(DSL) functions defined in: :class:`DataFrame`, :class:`Column`.\n",
              "\n",
              "To select a column from the :class:`DataFrame`, use the apply method:\n",
              "\n",
              "&gt;&gt;&gt; age_col = people.age\n",
              "\n",
              "A more concrete example:\n",
              "\n",
              "&gt;&gt;&gt; # To create DataFrame using SparkSession\n",
              "... department = spark.createDataFrame([\n",
              "...     {&quot;id&quot;: 1, &quot;name&quot;: &quot;PySpark&quot;},\n",
              "...     {&quot;id&quot;: 2, &quot;name&quot;: &quot;ML&quot;},\n",
              "...     {&quot;id&quot;: 3, &quot;name&quot;: &quot;Spark SQL&quot;}\n",
              "... ])\n",
              "\n",
              "&gt;&gt;&gt; people.filter(people.age &gt; 30).join(\n",
              "...     department, people.deptId == department.id).groupBy(\n",
              "...     department.name, &quot;gender&quot;).agg(\n",
              "...         {&quot;salary&quot;: &quot;avg&quot;, &quot;age&quot;: &quot;max&quot;}).sort(&quot;max(age)&quot;).show()\n",
              "+-------+------+-----------+--------+\n",
              "|   name|gender|avg(salary)|max(age)|\n",
              "+-------+------+-----------+--------+\n",
              "|PySpark|     M|       75.0|      50|\n",
              "|     ML|     F|      150.0|      60|\n",
              "+-------+------+-----------+--------+\n",
              "\n",
              "Notes\n",
              "-----\n",
              "A DataFrame should only be created as described above. It should not be directly\n",
              "created via using the constructor.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 105);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.select(['Name', 'Experience']).show()\n",
        "\n",
        "# if you want to select multiple columns/fields"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M9LAqH4ilt_h",
        "outputId": "67a8594c-e0a9-42cc-acc9-2e638776c3a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+----------+\n",
            "|     Name|Experience|\n",
            "+---------+----------+\n",
            "|    Krish|        10|\n",
            "|Sudhanshu|         8|\n",
            "|    Sunny|         4|\n",
            "|     Paul|         3|\n",
            "|   Harsha|         1|\n",
            "|  Shubham|         2|\n",
            "+---------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark['Name']\n",
        "\n",
        "# here the .show() function wont work"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wwZbU3uYa3JH",
        "outputId": "e3eeaa62-7ac2-407c-afed-ea018a0fe8f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Column<'Name'>"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.dtypes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UJ2rZbLEm2k7",
        "outputId": "28726912-0e72-4b7c-e4f6-4a9e644c1f2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Name', 'string'), ('age', 'int'), ('Experience', 'int'), ('Salary', 'int')]"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.describe().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "whnSGFELm2nf",
        "outputId": "17e46812-1f5c-46a6-e45d-ba7e318ee941"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------+------------------+-----------------+------------------+\n",
            "|summary|  Name|               age|       Experience|            Salary|\n",
            "+-------+------+------------------+-----------------+------------------+\n",
            "|  count|     6|                 6|                6|                 6|\n",
            "|   mean|  NULL|26.333333333333332|4.666666666666667|21333.333333333332|\n",
            "| stddev|  NULL| 4.179314138308661|3.559026084010437| 5354.126134736337|\n",
            "|    min|Harsha|                21|                1|             15000|\n",
            "|    max| Sunny|                31|               10|             30000|\n",
            "+-------+------+------------------+-----------------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### adding columns in data frame\n",
        "\n",
        "df_pyspark = df_pyspark.withColumn('Experience after 2 years', df_pyspark['Experience'] + 2)"
      ],
      "metadata": {
        "id": "AHQmfH4Jm2qE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E3uXm5nGm2ve",
        "outputId": "e1fedcaf-31a2-4bd3-ea49-c820937e2d0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---+----------+------+------------------------+\n",
            "|     Name|age|Experience|Salary|Experience after 2 years|\n",
            "+---------+---+----------+------+------------------------+\n",
            "|    Krish| 31|        10| 30000|                      12|\n",
            "|Sudhanshu| 30|         8| 25000|                      10|\n",
            "|    Sunny| 29|         4| 20000|                       6|\n",
            "|     Paul| 24|         3| 20000|                       5|\n",
            "|   Harsha| 21|         1| 15000|                       3|\n",
            "|  Shubham| 23|         2| 18000|                       4|\n",
            "+---------+---+----------+------+------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## drop the columns\n",
        "\n",
        "df_pyspark = df_pyspark.drop('Experience After 2 year')"
      ],
      "metadata": {
        "id": "EmdHHuEVm2yC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7pgM6Spym205",
        "outputId": "3e58dca9-0f96-40de-c974-b9aba8b2a646"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---+----------+------+------------------------+\n",
            "|     Name|age|Experience|Salary|Experience after 2 years|\n",
            "+---------+---+----------+------+------------------------+\n",
            "|    Krish| 31|        10| 30000|                      12|\n",
            "|Sudhanshu| 30|         8| 25000|                      10|\n",
            "|    Sunny| 29|         4| 20000|                       6|\n",
            "|     Paul| 24|         3| 20000|                       5|\n",
            "|   Harsha| 21|         1| 15000|                       3|\n",
            "|  Shubham| 23|         2| 18000|                       4|\n",
            "+---------+---+----------+------+------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### rename the column\n",
        "\n",
        "df_pyspark.withColumnRenamed('Name', 'New Name').show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aWSKrvXqm237",
        "outputId": "2cb6dc08-08d1-418c-a1e3-8710635ef7aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---+----------+------+------------------------+\n",
            "|  New Nme|age|Experience|Salary|Experience after 2 years|\n",
            "+---------+---+----------+------+------------------------+\n",
            "|    Krish| 31|        10| 30000|                      12|\n",
            "|Sudhanshu| 30|         8| 25000|                      10|\n",
            "|    Sunny| 29|         4| 20000|                       6|\n",
            "|     Paul| 24|         3| 20000|                       5|\n",
            "|   Harsha| 21|         1| 15000|                       3|\n",
            "|  Shubham| 23|         2| 18000|                       4|\n",
            "+---------+---+----------+------+------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 2\n",
        "\n",
        "- handling missing values\n",
        "- dropping columns\n",
        "- dropping rows\n",
        "- various parameter in dropping functionalities\n",
        "- handling missing values by mean, median, mode"
      ],
      "metadata": {
        "id": "YyVjqhG4pChj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName('Practice').getOrCreate()"
      ],
      "metadata": {
        "id": "ajX2Of6_ogKj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_2 = spark.read.csv('test2.csv', header=True, inferSchema=True)"
      ],
      "metadata": {
        "id": "vR3BcKq2pRAi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_2.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wMzk-XpBpRFZ",
        "outputId": "a79531cf-d410-487f-9d8a-926850fba763"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+----+----------+------+\n",
            "|     Name| age|Experience|Salary|\n",
            "+---------+----+----------+------+\n",
            "|    Krish|  31|        10| 30000|\n",
            "|Sudhanshu|  30|         8| 25000|\n",
            "|    Sunny|  29|         4| 20000|\n",
            "|     Paul|  24|         3| 20000|\n",
            "|   Harsha|  21|         1| 15000|\n",
            "|  Shubham|  23|         2| 18000|\n",
            "|   Mahesh|NULL|      NULL| 40000|\n",
            "|     NULL|  34|        10| 38000|\n",
            "|     NULL|  36|      NULL|  NULL|\n",
            "+---------+----+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dropping the columns\n",
        "df_2.drop('Name').show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G98OkaNCpRHz",
        "outputId": "348368d8-9d5e-4998-f68c-553f47efbd7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+----------+------+\n",
            "| age|Experience|Salary|\n",
            "+----+----------+------+\n",
            "|  31|        10| 30000|\n",
            "|  30|         8| 25000|\n",
            "|  29|         4| 20000|\n",
            "|  24|         3| 20000|\n",
            "|  21|         1| 15000|\n",
            "|  23|         2| 18000|\n",
            "|NULL|      NULL| 40000|\n",
            "|  34|        10| 38000|\n",
            "|  36|      NULL|  NULL|\n",
            "+----+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# drop rows (which have null values)\n",
        "df_2.na.drop().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g1Cp3WORpRKT",
        "outputId": "26c82985-20bd-42be-c8db-a6c3d426bdae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---+----------+------+\n",
            "|     Name|age|Experience|Salary|\n",
            "+---------+---+----------+------+\n",
            "|    Krish| 31|        10| 30000|\n",
            "|Sudhanshu| 30|         8| 25000|\n",
            "|    Sunny| 29|         4| 20000|\n",
            "|     Paul| 24|         3| 20000|\n",
            "|   Harsha| 21|         1| 15000|\n",
            "|  Shubham| 23|         2| 18000|\n",
            "+---------+---+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# df_spark.na.drop(how='any', thresh=None, subset=None)\n",
        "\n",
        "### how\n",
        "# default any\n",
        "# == any -> drop a row if it contains any nulls\n",
        "# == all -> drop a row only if all its values are null\n",
        "\n",
        "### thresh\n",
        "# default None\n",
        "# if specified, drop rows that have less than 'thresh' non-null values\n",
        "# this overwrites the 'how' parameter\n",
        "# eg :- 2, atleast 2 non-null values should be present\n",
        "\n",
        "### subset\n",
        "# str, tuple or list, optional\n",
        "# optional list of column names to consider"
      ],
      "metadata": {
        "id": "bc19e2g-pRNk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_2.na.drop(how=\"any\", thresh=2).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uMLz0eKSq46G",
        "outputId": "6a5e24d7-0756-41cb-898d-b9e200dac3ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+----+----------+------+\n",
            "|     Name| age|Experience|Salary|\n",
            "+---------+----+----------+------+\n",
            "|    Krish|  31|        10| 30000|\n",
            "|Sudhanshu|  30|         8| 25000|\n",
            "|    Sunny|  29|         4| 20000|\n",
            "|     Paul|  24|         3| 20000|\n",
            "|   Harsha|  21|         1| 15000|\n",
            "|  Shubham|  23|         2| 18000|\n",
            "|   Mahesh|NULL|      NULL| 40000|\n",
            "|     NULL|  34|        10| 38000|\n",
            "+---------+----+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_2.na.drop(how=\"any\", subset=['Experience']).show()\n",
        "# so in that specific column the null values rows will be eliminated"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZXPQuc16q5D3",
        "outputId": "d5393841-edbc-41d4-98a8-60812f114e12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---+----------+------+\n",
            "|     Name|age|Experience|Salary|\n",
            "+---------+---+----------+------+\n",
            "|    Krish| 31|        10| 30000|\n",
            "|Sudhanshu| 30|         8| 25000|\n",
            "|    Sunny| 29|         4| 20000|\n",
            "|     Paul| 24|         3| 20000|\n",
            "|   Harsha| 21|         1| 15000|\n",
            "|  Shubham| 23|         2| 18000|\n",
            "|     NULL| 34|        10| 38000|\n",
            "+---------+---+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# fil the missing values\n",
        "df_2.na.fill('Missing Values', ['Name', 'age']).show()\n",
        "\n",
        "# it should change of all but idk why it isnt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OktQ0qtrvS_I",
        "outputId": "148b3827-5e37-4b05-ca0c-f2e4c0f1448d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+----+----------+------+\n",
            "|          Name| age|Experience|Salary|\n",
            "+--------------+----+----------+------+\n",
            "|         Krish|  31|        10| 30000|\n",
            "|     Sudhanshu|  30|         8| 25000|\n",
            "|         Sunny|  29|         4| 20000|\n",
            "|          Paul|  24|         3| 20000|\n",
            "|        Harsha|  21|         1| 15000|\n",
            "|       Shubham|  23|         2| 18000|\n",
            "|        Mahesh|NULL|      NULL| 40000|\n",
            "|Missing Values|  34|        10| 38000|\n",
            "|Missing Values|  36|      NULL|  NULL|\n",
            "+--------------+----+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_2.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1IgptkGbvTCS",
        "outputId": "75bd5204-cc05-459e-9e7f-a4a3a8bdc819"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+----+----------+------+\n",
            "|     Name| age|Experience|Salary|\n",
            "+---------+----+----------+------+\n",
            "|    Krish|  31|        10| 30000|\n",
            "|Sudhanshu|  30|         8| 25000|\n",
            "|    Sunny|  29|         4| 20000|\n",
            "|     Paul|  24|         3| 20000|\n",
            "|   Harsha|  21|         1| 15000|\n",
            "|  Shubham|  23|         2| 18000|\n",
            "|   Mahesh|NULL|      NULL| 40000|\n",
            "|     NULL|  34|        10| 38000|\n",
            "|     NULL|  36|      NULL|  NULL|\n",
            "+---------+----+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`from pyspark.ml.feature import Imputer`\n",
        "\n",
        "- Imports Spark MLs Imputer, used to fill missing values (nulls) in numeric columns.\n",
        "\n",
        "- Works on DataFrames, not pandas.\n",
        "\n",
        "- Supports strategies:\n",
        "\"mean\"\n",
        "\"median\"\n",
        "\"mode\"\n",
        "\n",
        "`inputCols` -> columns that contain missing (null) values\n",
        "\n",
        "- must be numeric column\n",
        "\n",
        "`outputCols`\n",
        "- Creates new column names dynamically\n",
        "- Spark does not overwrite original columns\n",
        "- Original + imputed columns will both exist in the DataFrame\n",
        "\n",
        "`.setStrategy(\"median\")`\n",
        "- Tells Spark how to compute the replacement value\n",
        "\n",
        "`imputer.fit(df_pyspark)`\n",
        "- Computes the median for each input column from the data\n",
        "- This step learns the statistics (like training in sklearn)"
      ],
      "metadata": {
        "id": "5Aanh6X5w_gQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Imputer function (sklearn)\n",
        "\n",
        "from pyspark.ml.feature import Imputer\n",
        "\n",
        "imputer = Imputer(\n",
        "    inputCols=['age', 'Experience', 'Salary'],\n",
        "    outputCols=[\"{}_imputed\".format(c) for c in ['age', 'Experience', 'Salary']]\n",
        "    ).setStrategy(\"median\")\n",
        "\n",
        "# can change stratergy to mean, median or mode."
      ],
      "metadata": {
        "id": "aKQ2A6F5vTFS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add imputation cols to df\n",
        "imputer.fit(df_pyspark).transform(df_pyspark).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DljlUvudvTIR",
        "outputId": "2a83c330-5d79-4201-cf42-d017e0d952ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---+----------+------+------------------------+-----------+------------------+--------------+\n",
            "|     Name|age|Experience|Salary|Experience after 2 years|age_imputed|Experience_imputed|Salary_imputed|\n",
            "+---------+---+----------+------+------------------------+-----------+------------------+--------------+\n",
            "|    Krish| 31|        10| 30000|                      12|         31|                10|         30000|\n",
            "|Sudhanshu| 30|         8| 25000|                      10|         30|                 8|         25000|\n",
            "|    Sunny| 29|         4| 20000|                       6|         29|                 4|         20000|\n",
            "|     Paul| 24|         3| 20000|                       5|         24|                 3|         20000|\n",
            "|   Harsha| 21|         1| 15000|                       3|         21|                 1|         15000|\n",
            "|  Shubham| 23|         2| 18000|                       4|         23|                 2|         18000|\n",
            "+---------+---+----------+------+------------------------+-----------+------------------+--------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 3\n",
        "- filter operation\n",
        "- &, |, ==\n",
        "- ~"
      ],
      "metadata": {
        "id": "g3vdyG-yvQUO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder.appName('Practice').getOrCreate()"
      ],
      "metadata": {
        "id": "ffar9Ha2q5HD"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_3 = spark.read.csv('test1.csv', header=True,inferSchema=True)\n",
        "df_3.show()"
      ],
      "metadata": {
        "id": "YHIKv5Icq5Kc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02878789-bc03-4dd7-b0c4-48ddbf6b172f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---+----------+------+\n",
            "|     Name|age|Experience|Salary|\n",
            "+---------+---+----------+------+\n",
            "|    Krish| 31|        10| 30000|\n",
            "|Sudhanshu| 30|         8| 25000|\n",
            "|    Sunny| 29|         4| 20000|\n",
            "|     Paul| 24|         3| 20000|\n",
            "|   Harsha| 21|         1| 15000|\n",
            "|  Shubham| 23|         2| 18000|\n",
            "+---------+---+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### filter operation"
      ],
      "metadata": {
        "id": "8d25G-zf6NJu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# salary of people less than or equal to 20k\n",
        "df_3.filter(\"Salary<=20000\").show()"
      ],
      "metadata": {
        "id": "yM4qvQv2q5NI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52dba64c-e9bc-4edc-ba15-67437390566b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+---+----------+------+\n",
            "|   Name|age|Experience|Salary|\n",
            "+-------+---+----------+------+\n",
            "|  Sunny| 29|         4| 20000|\n",
            "|   Paul| 24|         3| 20000|\n",
            "| Harsha| 21|         1| 15000|\n",
            "|Shubham| 23|         2| 18000|\n",
            "+-------+---+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_3.filter(\"Salary<=20000\").select(['Name', 'age']).show()"
      ],
      "metadata": {
        "id": "Qa6AoQdLq5PV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d9ab575-ac67-40de-80e4-37c907b64168"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+---+\n",
            "|   Name|age|\n",
            "+-------+---+\n",
            "|  Sunny| 29|\n",
            "|   Paul| 24|\n",
            "| Harsha| 21|\n",
            "|Shubham| 23|\n",
            "+-------+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_3.filter(df_3['Salary']<=20000).show()"
      ],
      "metadata": {
        "id": "7p14ov95q5R2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70911d10-0fb6-48b3-bee3-a3f30690f353"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+---+----------+------+\n",
            "|   Name|age|Experience|Salary|\n",
            "+-------+---+----------+------+\n",
            "|  Sunny| 29|         4| 20000|\n",
            "|   Paul| 24|         3| 20000|\n",
            "| Harsha| 21|         1| 15000|\n",
            "|Shubham| 23|         2| 18000|\n",
            "+-------+---+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_3.filter((df_3['Salary']<=20000) &\n",
        "            (df_3['age']>=23)).show()"
      ],
      "metadata": {
        "id": "HgLw8Amaq5UN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a89e4a58-585c-441d-9a73-f9c26e08b108"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+---+----------+------+\n",
            "|   Name|age|Experience|Salary|\n",
            "+-------+---+----------+------+\n",
            "|  Sunny| 29|         4| 20000|\n",
            "|   Paul| 24|         3| 20000|\n",
            "|Shubham| 23|         2| 18000|\n",
            "+-------+---+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_3.filter(~(df_3['Salary']<=20000)).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SCZ2ztav7SzW",
        "outputId": "a7cf093f-d2c6-4e19-f357-ddf646bb63aa"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---+----------+------+\n",
            "|     Name|age|Experience|Salary|\n",
            "+---------+---+----------+------+\n",
            "|    Krish| 31|        10| 30000|\n",
            "|Sudhanshu| 30|         8| 25000|\n",
            "+---------+---+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 4\n",
        "\n",
        "- pyspark groupby nd aggregate functions"
      ],
      "metadata": {
        "id": "fjI0sDJRyzL_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName('Practice').getOrCreate()"
      ],
      "metadata": {
        "id": "lyRJvbds7gd6"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_4 = spark.read.csv('test3.csv',header=True, inferSchema=True)"
      ],
      "metadata": {
        "id": "anjTb7QJ7ggk"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_4.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JdppW5aw7gjK",
        "outputId": "52f5d426-439a-421c-b45e-55822cfa379e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+------------+------+\n",
            "|     Name| Departments|salary|\n",
            "+---------+------------+------+\n",
            "|    Krish|Data Science| 10000|\n",
            "|    Krish|         IOT|  5000|\n",
            "|   Mahesh|    Big Data|  4000|\n",
            "|    Krish|    Big Data|  4000|\n",
            "|   Mahesh|Data Science|  3000|\n",
            "|Sudhanshu|Data Science| 20000|\n",
            "|Sudhanshu|         IOT| 10000|\n",
            "|Sudhanshu|    Big Data|  5000|\n",
            "|    Sunny|Data Science| 10000|\n",
            "|    Sunny|    Big Data|  2000|\n",
            "+---------+------------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_4.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LzLkMVRl7glt",
        "outputId": "18ea7921-9ab6-48f0-cd8e-a5e01ab2359b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Name: string (nullable = true)\n",
            " |-- Departments: string (nullable = true)\n",
            " |-- salary: integer (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### groupby operation\n",
        "\n",
        "# groupby and aggregte functions work hand in hand.\n",
        "# first we should call groupby then we should call aggregate.\n",
        "\n",
        "# grouped to find the maximum salary\n",
        "df_4.groupBy('Name').sum().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iD9NdjzM_IQ2",
        "outputId": "1abbfedb-ce7b-42f3-da18-722081a25766"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-----------+\n",
            "|     Name|sum(salary)|\n",
            "+---------+-----------+\n",
            "|Sudhanshu|      35000|\n",
            "|    Sunny|      12000|\n",
            "|    Krish|      19000|\n",
            "|   Mahesh|       7000|\n",
            "+---------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# groupby departments which gives maximum salary\n",
        "df_4.groupBy('Departments').sum().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7EZVawNC_IUa",
        "outputId": "60fbf668-8243-4b6f-faaf-e71c4f2eaa26"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+-----------+\n",
            "| Departments|sum(salary)|\n",
            "+------------+-----------+\n",
            "|         IOT|      15000|\n",
            "|    Big Data|      15000|\n",
            "|Data Science|      43000|\n",
            "+------------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_4.groupBy('Departments').mean().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KJ2m0FC5_IXR",
        "outputId": "42f9d5d9-0f3f-4640-d2b7-7e254dfc4ed3"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+-----------+\n",
            "| Departments|avg(salary)|\n",
            "+------------+-----------+\n",
            "|         IOT|     7500.0|\n",
            "|    Big Data|     3750.0|\n",
            "|Data Science|    10750.0|\n",
            "+------------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_4.groupBy('Name').count().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iWvY8E4L_IZn",
        "outputId": "575f62d8-f8f8-457c-cd27-0eab0a8368fa"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-----+\n",
            "|     Name|count|\n",
            "+---------+-----+\n",
            "|Sudhanshu|    3|\n",
            "|    Sunny|    2|\n",
            "|    Krish|    3|\n",
            "|   Mahesh|    2|\n",
            "+---------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_4.groupBy('Departments').count().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OToCIrSF_Ib7",
        "outputId": "da1491e3-93ac-4ad3-d26d-b6043624fbb9"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+-----+\n",
            "| Departments|count|\n",
            "+------------+-----+\n",
            "|         IOT|    2|\n",
            "|    Big Data|    4|\n",
            "|Data Science|    4|\n",
            "+------------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_4.agg({'Salary':'sum'}).show()\n",
        "# total salary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OqsL6t00_IeM",
        "outputId": "ccfa7b9f-84e5-4e17-c96c-b45b7aa27473"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+\n",
            "|sum(Salary)|\n",
            "+-----------+\n",
            "|      73000|\n",
            "+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_4.groupBy('Name').max().show()\n",
        "\n",
        "# so see here even if we specific an column with string datatype but the max() function is applied on the numeric only\n",
        "# similarly for the count(), sum(), mean() defined above."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_7P2Ditv_Igd",
        "outputId": "c19d04ca-b664-4ec9-b665-9473f6e52d73"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-----------+\n",
            "|     Name|max(salary)|\n",
            "+---------+-----------+\n",
            "|Sudhanshu|      20000|\n",
            "|    Sunny|      10000|\n",
            "|    Krish|      10000|\n",
            "|   Mahesh|       4000|\n",
            "+---------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_4.groupBy('Name').min().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ReKrN1bf_IkC",
        "outputId": "446ff49b-a3b9-432c-df3a-33be9803cb50"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-----------+\n",
            "|     Name|min(salary)|\n",
            "+---------+-----------+\n",
            "|Sudhanshu|       5000|\n",
            "|    Sunny|       2000|\n",
            "|    Krish|       4000|\n",
            "|   Mahesh|       3000|\n",
            "+---------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 5\n",
        "\n",
        "MLib documentation\n",
        "- RDD techniques\n",
        "- DataFrame API (recent)"
      ],
      "metadata": {
        "id": "lKx7tO36yzrh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName('Practice').getOrCreate()"
      ],
      "metadata": {
        "id": "MUmBpd-ZBhnE"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# read the dataset\n",
        "training = spark.read.csv('test1.csv', header=True, inferSchema=True)"
      ],
      "metadata": {
        "id": "H4UFLH0aBroK"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training.show()\n",
        "\n",
        "# aim is to here understand 2 columns and predict the third one."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aEJVb_6rBrrG",
        "outputId": "9213a8b1-35be-4103-e78c-2242e0539b5f"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---+----------+------+\n",
            "|     Name|age|Experience|Salary|\n",
            "+---------+---+----------+------+\n",
            "|    Krish| 31|        10| 30000|\n",
            "|Sudhanshu| 30|         8| 25000|\n",
            "|    Sunny| 29|         4| 20000|\n",
            "|     Paul| 24|         3| 20000|\n",
            "|   Harsha| 21|         1| 15000|\n",
            "|  Shubham| 23|         2| 18000|\n",
            "+---------+---+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4-qKw_NOBruX",
        "outputId": "80514535-880b-4b8b-e0fa-a7c4e9e6b6cc"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Name: string (nullable = true)\n",
            " |-- age: integer (nullable = true)\n",
            " |-- Experience: integer (nullable = true)\n",
            " |-- Salary: integer (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XmcGFI6zDME8",
        "outputId": "13cb3645-868b-4091-9d05-53d0b924c492"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Name', 'age', 'Experience', 'Salary']"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# we have to create a way where i we can group all individual features.\n",
        "# vector assembler\n",
        "# group the independent features like this [Age, Experience]\n",
        "# then we treat the group as a new feature\n",
        "# [Age, Experience] --> new feature --> independent feature"
      ],
      "metadata": {
        "id": "e12Jjz89DMIq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import VectorAssembler\n",
        "featureassembler = VectorAssembler(inputCols=[\"age\", \"Experience\"], outputCol=\"Independent Features\")"
      ],
      "metadata": {
        "id": "0O76tTRlDMMv"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output = featureassembler.transform(training)"
      ],
      "metadata": {
        "id": "JHOvO3f0DMPH"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4OIKAGMLBhsH",
        "outputId": "24dcd929-ac1e-4604-d7ba-8ab3fd6d08d9"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---+----------+------+--------------------+\n",
            "|     Name|age|Experience|Salary|Independent Features|\n",
            "+---------+---+----------+------+--------------------+\n",
            "|    Krish| 31|        10| 30000|         [31.0,10.0]|\n",
            "|Sudhanshu| 30|         8| 25000|          [30.0,8.0]|\n",
            "|    Sunny| 29|         4| 20000|          [29.0,4.0]|\n",
            "|     Paul| 24|         3| 20000|          [24.0,3.0]|\n",
            "|   Harsha| 21|         1| 15000|          [21.0,1.0]|\n",
            "|  Shubham| 23|         2| 18000|          [23.0,2.0]|\n",
            "+---------+---+----------+------+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MlThN-6-E1qM",
        "outputId": "a1ff298f-fd82-4fe2-9977-143ec1fd0282"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Name', 'age', 'Experience', 'Salary', 'Independent Features']"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "finalized_data = output.select(\"Independent Features\", \"Salary\")"
      ],
      "metadata": {
        "id": "rmgNDRT6E1uA"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "finalized_data.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2YAMWKegE1xh",
        "outputId": "3fa490c8-eea4-489e-e0bc-5ca72951775c"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+------+\n",
            "|Independent Features|Salary|\n",
            "+--------------------+------+\n",
            "|         [31.0,10.0]| 30000|\n",
            "|          [30.0,8.0]| 25000|\n",
            "|          [29.0,4.0]| 20000|\n",
            "|          [24.0,3.0]| 20000|\n",
            "|          [21.0,1.0]| 15000|\n",
            "|          [23.0,2.0]| 18000|\n",
            "+--------------------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.regression import LinearRegression\n",
        "\n",
        "# train test split\n",
        "train_data, test_data = finalized_data.randomSplit([0.75, 0.25])\n",
        "regressor = LinearRegression(featuresCol = 'Independent Features', labelCol='Salary')\n",
        "regressor = regressor.fit(train_data)"
      ],
      "metadata": {
        "id": "yg09ivJnFU6W"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Coefficients\n",
        "regressor.coefficients"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ermuMRoYFU91",
        "outputId": "529144e7-416f-4645-93ac-9721004bd4c0"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DenseVector([-90.5483, 1608.7819])"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Intercepts\n",
        "regressor.intercept"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dl1wAGb2FVBF",
        "outputId": "712668d4-9362-49db-b7d0-c480b9b21701"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16079.13669064716"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Prediction\n",
        "pred_results=regressor.evaluate(test_data)"
      ],
      "metadata": {
        "id": "BkLkhtuoFVFz"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_results.predictions.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Pc5cRwSHTHV",
        "outputId": "36e2008a-2be8-4d75-f3e6-c6c2f67ed5ff"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+------+------------------+\n",
            "|Independent Features|Salary|        prediction|\n",
            "+--------------------+------+------------------+\n",
            "|          [23.0,2.0]| 18000|17214.090796328448|\n",
            "+--------------------+------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred_results.meanAbsoluteError, pred_results.meanSquaredError"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1f60XRp-HTK1",
        "outputId": "c20cec02-6760-4380-b0f3-4f5d34e27124"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(785.909203671552, 617653.276415653)"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 6\n",
        "\n",
        "# MLib - PySpark\n",
        "https://spark.apache.org/docs/latest/api/python/reference/pyspark.ml.html"
      ],
      "metadata": {
        "id": "lmN-LkXoy0er"
      }
    }
  ]
}